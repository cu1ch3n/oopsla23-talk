\documentclass[aspectratio=43,10pt]{beamer}

\usetheme[block=fill]{metropolis}
\usefonttheme[onlymath]{serif}
\setmonofont{iosevka-light.ttf}

\usepackage{appendixnumberbeamer}

\usepackage{booktabs}
\usepackage[scale=2]{ccicons}

\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}

\usepackage{minted}
\usemintedstyle{xcode}

\usepackage{xspace}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{url}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{mathtools}

\usepackage{ulem}

\usepackage{tikz}
\usetikzlibrary{tikzmark,calc}

\usepackage{pdfcomment}
\newcommand{\pdfnote}[1]{\marginnote{\pdfcomment[icon=note]{#1}}}
%\newcommand{\pdfnote}[1]{}

\input{macros.tex}

\pdfstringdefDisableCommands{%
  \def\\{}%
  \def\texttt#1{<#1>}%
}

\title{Greedy Implicit Bounded Quantification}
\subtitle{}
\author{
    \underline{Chen Cui}, Shengyi Jiang, Bruno C. d. S. Oliveira
}
\date{October 26, 2023}
\institute{The University of Hong Kong
\pdfnote{Good morning everyone. My name is Chen Cui. I am currently a PhD student at the University of Hong Kong. Today I am delighted to share our work: Greedy Implicit Bounded Quantification.}
}
\titlegraphic{\raggedleft\includegraphics[width=0.3\linewidth]{logo.png}}

\begin{document}

\maketitle

\begin{frame}[fragile]{Bounded Quantification}
Mainstream OOP languages (Java, Scala, C\#...) have polymorphic type systems with subtyping and \textbf{bounded quantification}.
\begin{minted}[escapeinside=||]{java}
public static |\tikzmark{codeblock}\highlight{<S extends Comparable>}| S min(S a, S b) {
    if (a.compareTo(b) <= 0) {
        return a;
    } else {
        return b;
    }
}
\end{minted}
The type of \texttt{min}: \tikzmark{mathblock}\highlight{$\forall{(\texttt{S} \le \texttt{Comparable})}$} ${.~\texttt{S} \to \texttt{S} \to \texttt{S}}$.

However, there is little work on \textbf{type inference} algorithms supporting bounded quantification.
\begin{tikzpicture}[remember picture, overlay]
    \node[align=center, text width=7cm] (bound) at ($(current page.center)+(2,0.1)$) {
    \begin{block}{Bounded Quantification}
    Gives subtyping bounds to type variables.
    \end{block}
    };
    \draw[->, line width=0.4mm, color=lightgray] ($(pic cs:codeblock)+(3,-0.2)$) .. controls +(0,-1) and +(0,1) .. ($(bound.north)+(0,-0.3)$);
    \draw[->, line width=0.4mm, color=lightgray] ($(pic cs:mathblock)+(1.1,0.4)$) .. controls +(0,1) and +(0,-1) .. ($(bound.south)+(0,0.1)$);
\end{tikzpicture}
\pdfnote{<read 1> Take this Java code as an example. It defines a generic method or a function min, which takes two arguments of type S and returns a value of the same type S. The <S extends Comparable> here defines a type variable S, and gives a bound Comparable to it. We may write the type of min in a mathematical way like this. Bounded Quantification is used to give subtyping bounds to type variables. So the quantifier is only bounded to range over the subtypes of Comparable. This is a widely used feature in OOP languages. However, ...}
\end{frame}

\begin{frame}[fragile]{Type Inference}
\textbf{Type inference} enables removing redundant type annotations

\begin{minted}[escapeinside=||]{java}
List<String> numbers = Arrays.asList("1", "2", "3", "4", "5");
List<Integer> even = numbers.stream()
                            .|\highlight{map}|(|\highlight{s}| -> Integer.valueOf(s))
                            .filter(number -> number % 2 == 0)
                            .collect(Collectors.toList());
\end{minted}
The type of \scala{map} in Java is:\\
\mintinline{java}{  <R> Stream<R> map(Function<? super T,? extends R> mapper)}
\begin{itemize}
    \item Type argument inference: \scala{map} is instantiated with type \scala{R = Integer}
    \item Argument inference: \scala{s} has type \scala{String}
\end{itemize}
\pdfnote{Type inference enables removing redundant type annotations from programs and can reduce the burden of programmers. When you write the code, the compiler fills the missing types for you and keeps your code very concise and more readable.\nl
Take the code also in Java as an example, it processes a list of strings representing numbers, and converts the strings into numbers,
and filters the even numbers. \nl
In this code, we don't need to provide the type annotations when using the function map, filter, etc. One thing to note here is that the list functions are polymorphic. Here is the type of the map function in Java.\nl
It introduces a type parameter R, takes a function from T to R, and returns a stream of type R. By type inference, Java will automatically instantiate R with type Integer, since the return type of the valueOf function is Integer.\nl
And it can also infer that s has type String, since numbers is a list of Strings. The algorithm will propagate the known type information and conclude that s has type String.
}
\end{frame}


\begin{frame}[fragile]{Research on OOP Type Inference}
Surprisingly little work devoted to practical OOP type inference
\begin{itemize}
    \item Most production compilers (Java/C\#, etc) use algorithms loosely based on:
    \begin{itemize}
        \item {\includegraphics[scale=.8]{beamericonarticle}} Benjamin C. Pierce, David N. Turner.\\
        \qquad \textbf{Local type inference}. TOPLAS 2000.
    \end{itemize}
    \item Scala is based on an improved form of Local type inference:
    \begin{itemize}
        \item {\includegraphics[scale=.8]{beamericonarticle}} Martin Odersky, Christoph Zenger, Matthias Zenger.\\
        \qquad \textbf{Colored local type inference}. POPL 2001.
    \end{itemize}
\end{itemize}
\textbf{Local type inference} suffers from some limitations. Next we will identify these limitations in Scala 2.
\pdfnote{
Type inference is very important in a modern programming language. But surprisingly, there is little work devoted to practical object-oriented type inference. Currently, most production compilers (Java/C\#, etc) use algorithms loosely based on local type inference. And their algorithms are not formally studied and some problems regarding unsoundness and incompleteness have been found.\nl
Scala is based on an improved form of Local type inference, namely colored local type inference. Though Local type inference is the most widely used technique for languages with bounded quantification. It suffers from some limitations.
	Next we will identify these limitations in Scala 2, and compare it with our algorithm.
}
\end{frame}


\begin{frame}[fragile]{Hard-to-synthesize arguments}

\alert{None can be applied}: \emph{local type argument synthesis} and \emph{bidirectional type checking}

\begin{minted}{scala}
def map[A, B](f: A => B, xs: List[A]): List[B] = ...
\end{minted}

\xmark~ Function \scala{mapPlus1} \alert{fails} to type check in Scala 2\\
\scala{def mapPlus1: List[Int] = map(x => 1 + x, List(1, 2, 3))}

\pause

\cmark~ Workaround 1: Provide \textbf{type annotations} to the function argument\\
\mintinline[escapeinside=||]{scala}{def mapPlus2: List[Int] = map((x|\highlight{: Int}|) => 1 + x, List(1, 2, 3))}

\pause

\cmark~ Workaround 2: Provide all the \textbf{instantiations} directly\\
\mintinline[escapeinside=||]{scala}{def mapPlus3: List[Int] = map|\highlight{[Int, Int]}|(x => 1 + x, List(1, 2, 3))}

\pdfnote{The first limitation is Hard-to-synthesize arguments. Local type inference uses two techniques to synthesize types: local type argument synthesis and bidirectional type checking. But there are some cases that non of them can be applied. \nl
We may define a map function in Scala like this. It has 2 type arguments, and takes a function from type A to type B, and a list of A, and returns a list of type B. However, when it is applied to an anonymous function. It fails to type check. We usually have several workarounds.\nl
One workaround is providing type annotations to the function argument. Like we can annotate x with Int here.\nl
Another workaround is providing all the instantiations directly. Like here we can manually instantiate both A and B with Int.
}
\end{frame}

\begin{frame}[fragile]{No support for interdependent bounds}
Local type inference \alert{forbids} the inference of type arguments with interdependent bounds.

Scala does provide some basic support for interdependent bounds

\begin{minted}{scala}
def idFun[A, B <: A => A](x: B): (A => A) = x
def idInt1: (Int => Int) = (x => x)
\end{minted}

\xmark~ Function \scala{idInt2} \alert{fails} to type check in Scala\\
\scala{def idInt2 = idFun(idInt1)}

\begin{itemize}
    \item \scala{A} is instantiated to $\bot$ (i.e. \scala{Nothing} in Scala), instead of $\tint$
    \item \scala{B} is instantiated to $\tint \to \tint$
    \item \xmark~ does not conform to \scala{B <: A => A}
    \begin{itemize}
        \item \xmark~ $\tint \to \tint \le \bot \to \bot$ is not true
    \end{itemize}
\end{itemize}
\pdfnote{The second limitation is No support for interdependent bounds. Local type inference forbids the inference of type arguments with interdependent bounds, because they could not find a complete algorithm that deals with such kind of bounds. Scala does provide some basic support for interdependent bounds, but it fails frequently.\nl
If we define two identity functions, idFun is from type B to type A to A, but the bound of B depends on A, another one is from Int to Int. In Scala, we cannot apply idFun to idInt1, because Scala wrongly instantiate A with bottom (which is Nothing in Scala) instead of Int.\nl
It does not conform to the bound restriction that B is the subtype of A to A, so it is rejected.
}
\end{frame}

\begin{frame}[fragile]{No best argument}
The type variable to instantiate appears \textbf{invariantly} in the output type\\
The constraints are not enough to decide a \textbf{unique} instantiation
\begin{minted}{scala}
def snd[A]: (Int => A => A) = (x => y => y)
def id = snd(1)
\end{minted}
The type of \scala{id} is inferred as $\bot \to \bot$ in Scala\\
\xmark~ Thus \scala{id} cannot be applied further
\pdfnote{When the type variable to instantiate appears invariantly in the output type, but the constraints are not enough to decide a unique instantiation, local type inference fails to provide any instantiations. In such cases, Scala still infers a type, but the type can be meaningless. \nl
For example, when applying the function snd to 1, the constraints are not enough to decide a unique instantiation of A. Scala still infers the type of id as bottom to bottom. But it is meaningless, id cannot be applied further.\nl
Besides the three points we have mentioned, there are still some other problems of local type inference.
}
\end{frame}


\begin{frame}[fragile]{Higher-Ranked Type Inference}
Take a polymorphic function as the argument of another function
\begin{itemize}
    \item Rank-1 type: $\all[\ta][\tint]{\ta \to \ta \to \tint}$
    \item Rank-2 type: $(\all[\ta][\tint]{\ta \to \ta}) \to \tint$
    \item ...
\end{itemize}
\begin{minted}{scala}
def k(f: Int => Int) = 1
def g(f: ([A <: Int] => A => A) => Int) = 1
\end{minted}
\xmark~ \scala{f} \alert{fails} to types check\\
\scala{def f = g(k)}
\begin{itemize}
    \item \scala{k} has type $(\tint \to \tint) \to \tint$
    \item \scala{g} accepts argument with type $(\all[\ta][\tint]{\ta \to \ta}) \to \tint$
    \item  \xmark~ $(\tint \to \tint) \to \tint \le (\all[\ta][\tint]{\ta \to \ta}) \to \tint$ is rejected in Scala
    \begin{itemize}
        \item due to its lack of \textbf{implicit polymorphism}
    \end{itemize}
\end{itemize}
\pdfnote{Finally, the subtyping relation employed in local type inference is restrictive and prohibits type-checking many programs
with higher-rank types. In rank-1 types, all quantifiers are at the start of the type. But higher-rank types allow us to freely decide the positions of the quantifiers. it is very useful when we would like take a polymorphic function as the argument of another function.\nl
In the code snippet below, k has type (Int -> Int) -> Int, and g is a function that accepts arugument with this type. We would expect the type inference algorithm can implicitly instantiate A with Int, so that we can apply g to k. However, this fails to type check in Scala due to its lack of implicit polymorphism.}
\end{frame}

%\section{\texorpdfstring{\name}{Fsubb} Calculus}


\begin{frame}[fragile]{\name Calculus}

\name extends {$F^{e}_{\le}$\xspace} calculus\footnote{Jinxu Zhao, Bruno C. d. S. Oliveira. Elementary Type Inference. ECOOP 2022.} with bounded quantification

\begin{itemize}
    \item a variant of kernel $F_\le$
    \begin{itemize}
        \item \textbf{Global} type inference (long-distance constraints)
        \item \textbf{Implicit instantiation} for monotypes (type argument inference)
        \begin{itemize}
            \item $(\tint \to \tint) \to \tint \le (\all[\ta][\tint]{\ta \to \ta}) \to \tint$
        \end{itemize}
        \item \textbf{Explicit type application} for polytypes (\textbf{impredicative polymorphism})
        \begin{itemize}
            \item $(\Lambda \ta.~ \lam{x}: \all[\ta][\top]{\ta \to \ta})~@(\all[\tb][\top]{\tb \to \tb})$
        \end{itemize}
%        \item No inference of \textbf{Top} and \textbf{Bottom} types
        \item A \textbf{sound}, \textbf{complete} and \textbf{decidable} algorithm
    \end{itemize}
\end{itemize}
Philosophy: infer easy instantiations; use explicit annotations for hard instantiations
\pdfnote{Next we will start to introduce our calculus, and our calculus can solve the problem we mentioned in local type inference.\nl
Our calculus extends the earlier work (Elementary type inference) with bounded quantification. It is a variant of kernel Fsub. Different from local type inference, it employs global type inference, so it is capable of solving long distance constraints.\nl
It follows the similar philosophy as Elementary Type Inference, we only infer easy instantiations, and use explicit annotations for hard instantiations. So our system has the implicit instantiation for monotypes, like the example we showed before. We can implictly instantiate A with Int. For hard instantiations like polytypes. We uses explicit type application to allow use provide the instantiations.\nl
%And we have no inference of Top and bottom types.\nl
And our calculus comes with a sound, complete and decidable algorithm which is formally studied. This is very important for a type inference algorithm. With soundness and completeness, the algorithm is guaranteed to be consistent with the declarative specification and the algorithm is guaranteed to terminate.
}
\end{frame}

\begin{frame}[fragile]{Syntax}
$$ \begin{array}{l@{\quad}lcl}
    \text{Type variables}\quad     & \ta, \tb
    \\[1mm]
    \text{Types}\quad              & A, B, C                      & ::= & \quad
    1 \mid \ua \mid \newRule{\all A} \mid A\to B  \mid \top \mid \bot
    \\
    \text{Expressions}\quad        & e, t                         & ::= & \quad
    x \mid () \mid \lam e \mid e_1~e_2 \mid (e:A) \mid	e~@A \mid
    \newRule{\tlam e : A }
    \\
    \text{Typing contexts}\quad    & \newRule{\tenv} & ::= & \quad
    \nil  \mid \tenv,x:A \mid \newRule{\tenv,\ua\le A}
    \\
    \text{Subtyping contexts}\quad & \Psi                         & ::= & \quad
    \tenv \mid \newRule{\Psi,a \sle A}
    \vspace{0.5em}
  \end{array}$$

Universal types $\all A$ and type abstractions $\tlam e : A$ now
incorporate a bound $B$ to support bounded quantification

\pdfnote{
This is the syntax of our calculus. Compared to elementary type inference. The change is that the Universal types and type abstractions now incorporate a bound B to support bounded quantification.
}
\end{frame}

\begin{frame}[fragile]{Declarative Subtyping Rules}
\framebox{$\Psi \vdash A \le B $} \hfill A is a subtype of B

\begin{mathparshrink}
    \inferrule*[right=$\mathtt{{\le}Unit}$]
    {~}{\Psi \vdash 1 \le 1 \elb{\lam[(x:1)]
        x}}[\mathtt{{\le}Unit}]\label{infrule:sub_unit}
    \and
    \inferrule*[right=$\mathtt{{\le}\top}$]
    {~}{ \Psi \vdash A \le \top
      \elb{\lam[(x:|A|)]{\text{()}}}}[\mathtt{{\le}\top}]\label{infrule:sub_top}
    \and
    \inferrule*[right=$\mathtt{{\le}\bot}$]
    {~}{ \Psi \vdash \bot \le A \elb{\lam[(x:\forall
          a.~a)]{x~@~|A|}}}[\mathtt{{\le}\bot}]\label{infrule:sub_bot}
    \and
    \inferrule*[right=$\mathtt{{\le}Var}$]
    {\ua\ule B\in\Psi\elb{*}}{\Psi\vdash \ua\le \ua \elb{\lam[(x:|a|)]
        x}}[\mathtt{{\le}Var}]\label{infrule:sub_var}
    \and
    \inferrule*[right=$\mathtt{{\le}VarTrans}$]
    {\ua\ule B\in\Psi\elb{Co_1: |a \to B|}\quad \Psi\vdash B\le
      A\elb{Co_2}}{\Psi\vdash \ua\le A \elb{\lam[(x:|a|)]
        Co_2~(Co_1~x)}}[\mathtt{{\le}VarTrans}]\label{infrule:sub_vartrans}
    \and
    \inferrule*[right=$\mathtt{{\le}{\to}}$]
    {\Psi \vdash B_1 \le A_1 \elb{Co_1} \quad \Psi \vdash A_2 \le B_2
      \elb{Co_2}}
    {\Psi\vdash A_1\to A_2 \le B_1\to B_2
      \elb{\lam[(f:|A_1 \to A_2|)]{\lam[(x:|B_1|)] Co_2~(f~(Co_1~x))}}
    }[\mathtt{{\le}{\to}}]\label{infrule:sub_arr}
    \and
    \highlight{\inferrule*[right=$\mathtt{{\le}\forall L}$]
    {\Psi\vdash^m\tau\quad\Psi\vdash \tau\le B\elb{Co_2}\quad \Psi\vdash
      [\tau/\ta] A \le C \elb{Co_1}\quad  C \text { is not a $\forall$ type} }
    {\Psi\vdash \all A \le C \elb{\lam[(x:|\all A|)]
        Co_1~)((x~@~|\tau|)~Co_2)}}[\mathtt{{\le}\forall L}]\label{infrule:sub_foralll}}
    \and
    \inferrule*[right=$\mathtt{{\le}\forall}$]
    {\Psi\vdash B_1\le B_2\elb{*}\quad\Psi\vdash B_2\le B_1\elb{Co_2}\quad\Psi,
      \ta\sle B_2 \vdash A_1 \le A_2 \elb{Co_1}}
    {\Psi\vdash \all[\ta][B_1] A_1 \le
      \all[\ta][B_2]{A_2}\elb{\lam[(x:|\all[a][B_1] A_1|)]{\tlamf{\lam[(f:a\to
              |B_2|)]Co_1~((x~@~a)~(\lam[(x:a)] Co_2~(f~x)
            ))}}}}[\mathtt{{\le}\forall}]\label{infrule:sub_forall}
  \end{mathparshrink}
\pdfnote{
These are the declarative subtyping rules of our system. It is based on standard higher-ranked polymorphic systems. The difference between our system and the elementary type inference is that we have the variable transitivity rule, and all the foralls now incorporate a bound. These two differences introduce most of the difficulties in proofs, and motivate us to rethink the question: what is monotype?
}
\end{frame}

\begin{frame}{Non-syntactical Monotype}
	transitivity
\end{frame}


\begin{frame}{Non-syntactical Monotype}
Finding implicit instantiations is \textbf{greedy} in existing predicative HRP approaches:

\textbf{Property}: monotype subtyping implies equality of monotypes
$$\tau_1 \le \tau_2 \Longrightarrow \tau_1 = \tau_2$$

For example, $a$ in $a \le \tint$ should not be regarded as monotype, since $a \le \tint \vdash a \le \tint$ but $a \ne \tint$.

$$\inferrule*[right=$\mathtt{{\le}VarTrans}$]
    {\ua\ule B\in\Psi\elb{Co_1: |a \to B|}\quad \Psi\vdash B\le
      A\elb{Co_2}}{\Psi\vdash \ua\le A \elb{\lam[(x:|a|)]
        Co_2~(Co_1~x)}}[\mathtt{{\le}VarTrans}]\label{infrule:sub_vartrans}
$$

Only type variables with bound $\top$ are regarded as monotypes in \name.

\pdfnote{In existing predicative higher-ranked polymorphism approaches, finding implicit instantiations is greedy.\nl
All such approaches rely on the property that monotype subtyping implies the equality of monotypes. This ensures that if the first instantiation works, then it must also work for subsequent instantiations. However, without care, the property easily breaks in the presence of more expressive subtyping relations, like bounded quantification.\nl
For example, a in ... \nl
Therefore, in our system, only type variables with bound top are regarded as monotypes.
}
\end{frame}

\begin{frame}{The Gap between the Declarative and the Algorithmic Systems}
$$
\inferrule*[right=$\mathtt{{\le}\forall L}$]
    {\Psi\vdash^m\newRule{\tau}\quad\Psi\vdash \newRule{\tau}\le B\elb{Co_2}\quad \Psi\vdash [\newRule{\tau}/\ta] A \le C \elb{Co_1}\quad  C \text { is not a $\forall$ type} }
    {\Psi\vdash \all A \le C \elb{\lam[(x:|\all A|)] Co_1~)((x~@~|\tau|)~Co_2)}}[\mathtt{{\le}\forall L}]
$$

The monotype $\newRule{\tau}$ is \textbf{guessed} in the declarative system.

In the algorithm, we
\begin{itemize}
    \item replace it by a placeholder \textbf{(existential variable)} to solve
    \item put all the todos in a unified list (\textbf{worklist}): track the scope easily
\end{itemize}
$$\Gamma \Vdash \forall (\ta \le B) .~ A \le C \longrightarrow \Gamma, \newRule{\ea} \Vdash \newRule{\ea} \le B \Vdash [\newRule{\ea} / \ta]A \le C$$
\pdfnote{... The worklist is like a stack, each time we peek the top of the stack, follow the instructions of the rules, like popping the top out, or add some new todos into the stack. When the worklist becomes empty, we succeed in typing. Otherwise, if it has no rule to apply, we know that the typing fails.}
\end{frame}

\begin{frame}[fragile]{A Sound but Incomplete Variant with Monotype Subtyping}
	Type variables with \textbf{mono bounds} are also regarded as monotypes.
\begin{mathparshrink}
  \inferrule*[right=$\mathtt{MTVarRec}$]
  {\ta\le A \in \Psi\quad \Psi \vdash^m A}{\Psi \vdash^m \ta}
\end{mathparshrink}

It now can be extended to deal with such nominal subtyping:
$\nil, \tshape \le \top, \tcircle \le \tshape \Vdash \all[\ta][\tshape]
          a\to a\to a \le \tcircle \to \tshape \to \tshape$
\begin{itemize}
	\item[\xmark] \name fails to type check ($\tshape$ is not a monotype in \name)
	\item[\cmark] The variant succeeds by picking
	 $\tshape$, leading to $\tshape \to \tshape \to \tshape \le
  \tshape \to \tcircle \to \tshape$
\end{itemize}
          
	\pdfnote{With this rule, we can accept more programs where implicit
instantiation can use type variables with monotype bounds. And it now can be extended to deal with such nominal subtyping. }
\end{frame}

\begin{frame}[fragile]{Conclusion}
    \begin{itemize}
        \item A calculus extending \elementary to \textbf{bounded quantification} and inherits its more modest approach to global type inference
        \item A predictable and easy-to-implement algorithm that is sound and complete w.r.t the declarative system
        \item A variant can infer types for more programs at the cost of completeness
        \item All theorems are formally verified in the Abella proof assistant (LOC: 24,919)
%        \item In the future, we will try to adapt the current algorithm to a non-greedy one to support nominal subtyping
    \end{itemize}
\end{frame}

\end{document}